{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2289d74a",
   "metadata": {},
   "source": [
    "Using input output pair to train RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe26c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the input-output pairs from the npy files\n",
    "input_pairs_all = np.load('input_pairs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87299e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d651d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_time_steps = input_pairs_all.shape[1] // 2\n",
    "num_freq_bins = input_pairs_all.shape[2]\n",
    "num_channels = input_pairs_all.shape[3]\n",
    "\n",
    "# Ensure the input_pairs_all has an even number of time steps\n",
    "if input_pairs_all.shape[1] % 2 != 0:\n",
    "    input_pairs_all = input_pairs_all[:, :-1, :, :]\n",
    "\n",
    "# Define your RNN-based generative model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(num_time_steps, num_freq_bins * num_channels), return_sequences=True))\n",
    "model.add(Dense(num_freq_bins * num_channels, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "# Create a generator for input-output pairs\n",
    "def batch_generator(input_pairs, batch_size):\n",
    "    num_samples = len(input_pairs)\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        excerpt = indices[start_idx:start_idx + batch_size]\n",
    "        batch = input_pairs[excerpt]\n",
    "\n",
    "        # Split the batch into input and output parts\n",
    "        input_batch = batch[:, :num_time_steps, :].reshape(-1, num_time_steps, num_freq_bins * num_channels)\n",
    "        output_batch = batch[:, num_time_steps:, :].reshape(-1, num_time_steps, num_freq_bins * num_channels)\n",
    "\n",
    "        yield input_batch, output_batch\n",
    "\n",
    "input_pairs_generator = batch_generator(input_pairs_all, batch_size)\n",
    "\n",
    "# Train the model using the generator\n",
    "for epoch in range(num_epochs):\n",
    "    for input_batch, output_batch in input_pairs_generator:\n",
    "        model.train_on_batch(input_batch, output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf7bb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "seed_sequence = input_pairs_all[0:1, :num_time_steps, :, :]\n",
    "seed_sequence_reshaped = seed_sequence.reshape(-1, num_time_steps, num_freq_bins * num_channels)\n",
    "\n",
    "# Generate new music using the trained model\n",
    "generated_music2 = []\n",
    "for _ in range(num_time_steps):  # Replace num_time_steps with the desired length of the generated music\n",
    "    predictions = model.predict(seed_sequence_reshaped)\n",
    "    generated_music2.append(predictions[:, -1:, :])\n",
    "    seed_sequence_reshaped = np.concatenate([seed_sequence_reshaped[:, 1:, :], predictions[:, -1:, :]], axis=1)\n",
    "\n",
    "# Convert the generated_music list to a numpy array\n",
    "generated_music2 = np.concatenate(generated_music2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a7f02",
   "metadata": {},
   "source": [
    "Using model to create new music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1484f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 0.0\n",
    "max_value = 1.0\n",
    "\n",
    "# Denormalization - Apply the formula element-wise to the entire array\n",
    "denormalized_music2 = (generated_music2 * (max_value - min_value)) + min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a640b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "# Set the sampling rate for the generated music (replace 44100 with your desired sampling rate)\n",
    "sampling_rate = 44100\n",
    "\n",
    "# If 'denormalized_music' contains stereo audio (2 channels), use this:\n",
    "denormalized_music2 = np.int16(denormalized_music2 * 32767)  # Scale the denormalized values to 16-bit integers\n",
    "wavfile.write('generated_music2.wav', sampling_rate, denormalized_music2)\n",
    "\n",
    "# If 'denormalized_music' contains mono audio (1 channel), use this:\n",
    "denormalized_music_mono2 = denormalized_music2[:, :, 0]  # Extract the first channel\n",
    "denormalized_music_mono2 = np.int16(denormalized_music_mono2 * 32767)  # Scale the denormalized values to 16-bit integers\n",
    "wavfile.write('generated_music_mono2.wav', sampling_rate, denormalized_music_mono2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5996957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "# Set the sampling rate for the generated music (replace 44100 with your desired sampling rate)\n",
    "sampling_rate = 44100\n",
    "\n",
    "# If 'denormalized_music' contains stereo audio (2 channels), use this:\n",
    "denormalized_music2 = np.int16(denormalized_music2 * 32767)  # Scale the denormalized values to 16-bit integers\n",
    "\n",
    "# If 'denormalized_music' contains mono audio (1 channel), use this:\n",
    "# denormalized_music_mono = denormalized_music[:, :, 0]  # Extract the first channel\n",
    "# denormalized_music_mono = np.int16(denormalized_music_mono * 32767)  # Scale the denormalized values to 16-bit integers\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Open a streaming stream\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=2,  # Use 1 for mono or 2 for stereo\n",
    "                rate=sampling_rate,\n",
    "                output=True)\n",
    "\n",
    "# Play the audio\n",
    "stream.write(denormalized_music2.tobytes())\n",
    "\n",
    "# Stop the stream and close the PyAudio object\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673758b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
